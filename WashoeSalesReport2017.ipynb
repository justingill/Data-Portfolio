{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Washoe County 2017 Sales Report Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is analysis, we will look into the [Washoe County Sales Report Data](https://www.washoecounty.us/assessor/online_data/sales_reports.php). This is a dataset that includes data on sales made in Washoe County during the 2017 fiscal year. We will clean this data up and use it to get an insight into the housing market in Washoe County. We can also apply regression to this dataset and predict housing prices based on different features included in the Sales Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://cdnparap100.paragonrels.com/ParagonImages/Property/P10/NNRMLS/170012273/0/0/0/662321a8ae87b96b5ef6e001d90e839e/15/2301c3cce54ff5e8c05025ff3c970831/170012273.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Import Libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Read in data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now read in our data from the Washoe County website given in xls format. \n",
    "* [Washoe Sales Report Link](https://www.washoecounty.us/assessor/online_data/sales_reports.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'RDEQISales2017.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-1a1feda584a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msales\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'RDEQISales2017.xls'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msheet_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Sheet1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    116\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, skiprows, skip_footer, index_col, names, usecols, parse_dates, date_parser, na_values, thousands, convert_float, converters, dtype, true_values, false_values, engine, squeeze, **kwds)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     return io._parse_excel(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    292\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 294\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    295\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'RDEQISales2017.xls'"
     ]
    }
   ],
   "source": [
    "sales = pd.read_excel('RDEQISales2017.xls',sheet_name='Sheet1',header=1,na_values=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what was read in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's extract some basic information from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Let's get a better understanding of our data!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am just exploring the dataset a bit, I was interested in the APN column and wanted to know more about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales[sales['APN'] == sales['APN'].value_counts().index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it seems to be a type of building code that represents certain buildings in Washoe County."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in analyzing sales of homes, we must only consider data that has a building type and address entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should look at the different type of buildings to see the variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type = sales['BldgType'].value_counts().index\n",
    "sales['BldgType'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have started with 13,500 data entries and only have building types for 12,047 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Data Entries: {}, Percent of data without a street address or type of building or stories entries entries: {:.2f}%'.format(\n",
    "    len(sales[(sales['BldgType'].isna()) | (sales['Situs'].isna()) | (sales['Stories'].isna())]),\n",
    "    len(sales[(sales['BldgType'].isna()) | (sales['Situs'].isna() | (sales['Stories'].isna()))])\n",
    "    /len(sales)*100))\n",
    "\n",
    "messy = sales[(sales['BldgType'].notna()) & (sales['Situs'].notna()) & (sales['Stories'].notna())].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we essentially have lost 14% of the data from the original sales report as they do not have a address, building type, or stories entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now dig deeper into the data. Let's check out our dataframe once again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 11,618 entries from 13,500 original entries. Let's look at the value count of the 'BldgType' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy['BldgType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we  see there are 63 different values in the column. This is way too many and we can shrink this down a little and aggregate some entries together, so let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Cleaning our Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a dictionary of replacement values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "building_type_dict = {'Sgl Fam Res ':'Residential House', 'Townhse End':'End Townhouse','Mixed Retail w/ Resid. Units':'Store',\n",
    "                      'Townhse Ins':'Middle Townhouse', 'Multiple Res (Low Rise)':'Low Rise Apartment',\n",
    "                      'HiRise Condo':'High Rise Condo', 'Parking Level':'Parking',\n",
    "                      'Industrial Flex Building':'Industrial Building', 'Retail Store':'Store',\n",
    "                     'Discount Store':'Store', 'Service Repair Garage':'Repair Garage',\n",
    "                      'Hotel, Limited Service':'Hotel', 'Hotel Condo':'Hotel',\n",
    "                     'Neighborhood Shopping Ctr':'Shopping Center','Fast Food Restaurant':'Restaurant',\n",
    "                     'Mini-Warehouse':'Warehouse','Mega Warehouse':'Warehouse',\n",
    "                      'Equipment (Shop) Building':'Equipment Shop','Hotel, Full Service':'Hotel',\n",
    "                     'Convenience Market':'Store','Industrials, Light Mftg.':'Industrial Building',\n",
    "                     'Shell, Office':'Office Building','Regional Shopping Center':'Shopping Center',\n",
    "                     'Dental Office/Clinic':'Medical Building','Mini-Lube Garage':'Repair Garage',\n",
    "                     'Apartment':'Low Rise Apartment','Lt. Commercial Utility Build.':'Industrial Building',\n",
    "                     'Community Shopping Center':'Shopping Center','Multiple Res. (Sen. Citizen)':'Group Care Home',\n",
    "                     'Theater - Live Stage':'Entertainment Building','Automotive Center':'Car Dealership',\n",
    "                     'Market':'Store','Veterinary Hospital':'Medical Building',\n",
    "                     'Distribution Warehouse':'Warehouse','Clubhouse':'Country Club',\n",
    "                     'Storage Garage':'Storage','Storage Warehouse':'Storage',\n",
    "                     'Supermarket':'Store','Automobile Showroom':'Entertainment Building',\n",
    "                     'Fire Station (Volunteer)':'Fire Station','Bowling Center':'Entertainment Building',\n",
    "                     'Shell, Neigh. Shop. Ctr.':'Shopping Center','Service Garage Shed':'Repair Garage',\n",
    "                     'Shed Office Structure':'Office Building','Handball-Racquetball Club':'Country Club',\n",
    "                     'Discount Warehouse Store':'Store','Medical Office':'Medical Building',\n",
    "                     'MH Real Prop':'MH Real Prop','Office Building':'Office Building',\n",
    "                     'Duplex':'Duplex','Conversion':'Conversion','Restaurant':'Restaurant',\n",
    "                     'Motel':'Motel','Bar/Tavern':'Bar','Casino':'Entertainment Building','Bank':'Bank',\n",
    "                     'Church':'Church','Barber Shop':'Barber Shop','Day Care Center':'Day Care Center',\n",
    "                     'Group Care Home':'Group Care Home','Country Club':'Country Club',\n",
    "                     'Restroom Building':'Restroom Building','Classroom':'Classroom','Dispensary':'Dispensary'}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy['BldgType'] = messy['BldgType'].map(building_type_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now mapped the dictionary to our column, let's look at what it did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy['BldgType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy['BldgType'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect, we changed all the column values and ended with how many we started with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now create new columns based off previous columns. This is a bit of feature engineering that will help us better visualize our data and extract more useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make a 'month','day' and 'street' column based off the 'Sales Date' and 'Situs' columns. We also go about dropping some columns that are not necessary to our analysis at the moment and are full of null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messy['Sale Month'] = messy['Sales Date'].apply(lambda x: int(x.split('/')[0]))\n",
    "messy['Sale Day'] = messy['Sales Date'].apply(lambda x: int(x.split('/')[1]))\n",
    "messy['Street'] = messy['Situs'].apply(lambda x: ' '.join(x.split()[1:]))\n",
    "\n",
    "#While we are at it let's also drop the columns Add Rec, Bsmt Type, Mailing2\n",
    "cleaned = messy.drop(['Situs','Sales Date' ,'Add Rec', 'Bsmt Type', 'Mailing2'],axis=1).copy()\n",
    "\n",
    "cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(cleaned.isnull())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see we are very close to cleaning our data entirely for our analysis. We will export this cleaner version of our data to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned.to_csv('Cleaned_WashoeSalesReport2017.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we go on and choose a subset of the data for our analysis, we should notice a interesting feature of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the different bins of the sales price on residential houses we can see how the data blows up at certain higher million dollar sales prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice weird trend in data\n",
    "total_residential = cleaned[(cleaned['BldgType'] == 'Residential House')]\n",
    "\n",
    "house_less_than = [cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 1e6)],\n",
    "                   cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 5e6)],\n",
    "                   cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 10e6)],\n",
    "                   cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 15e6)],\n",
    "                   cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 18e6)],\n",
    "                   cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                           & (cleaned['Sale Price'] < 19e6)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_res = [1,5,10,15,18,19]\n",
    "\n",
    "for price,data in list_res,house_less_than:\n",
    "    print('Houses less than {} million: {}'.format(price,len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice we get a reasonable change from 1-5 million. We get a total of 77 houses sold from 5-18 million and a total of 3 sold from 10-18 million. Very oddly, we now notice an increase of 78 houses between 18-19 million! This was odd to see and I do not know what caused this in the data. If I had to make a guess I would say it has something to do with housing developers buying large quantities of houses at once, but I cannot be exactly sure and it is fairly unimportant to this particular analysis since we will be dealing with houses under a million dollars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though it will not affect our analysis, it is a very interesting trend to see in something like the Washoe County Sales Report since this represents some type of real event!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Choosing a subset of our data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned our data up so that it can be useful, we may now take the subset we are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_more_mil = cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                         & (cleaned['Sale Price'] >= 1e6)].copy()\n",
    "\n",
    "percent = len(house_more_mil)/len(total_residential)\n",
    "\n",
    "print('Percentage of residential houses over 1 million dollars: {:.2f}%'.format(percent*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have are essentially going to leave out about 7% of our cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we grab the residential houses below or equal to a million dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house = cleaned[(cleaned['BldgType'] == 'Residential House') \n",
    "                            & (cleaned['Sale Price'] < 1e6)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may start to analyze the data on residential homes in Washoe County. Let's see what the minimum and maximum price of a residential house sold in Washoe County was in 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_price_min,house_price_max = (residential_house['Sale Price'].min(),\n",
    "                                   residential_house['Sale Price'].max())\n",
    "\n",
    "print('Min: {} , Max: {} '.format(house_price_min,house_price_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, $27,019! Very interesting, let's look at that entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house[residential_house['Sale Price'] \n",
    "                  == residential_house['Sale Price'].min()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like a reasonable entry, but is no doubt an odd/interesting one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualizations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to answer some questions about our data by using some visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in answering questions such as,\n",
    "* How much does a house cost in Washoe County?\n",
    "* What months are most popular for houses to be sold in?\n",
    "* Where are homebuyers moving in from?\n",
    "* How much square footage in a house can a person expect in Washoe County?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0,1e5,2e5,3e5,4e5,5e5,6e5,7e5,8e5,9e5,10e5]\n",
    "\n",
    "norm_sales = pd.cut(residential_house['Sale Price'],\n",
    "                    bins).value_counts(sort=False,\n",
    "                                       normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_sales.plot.bar(rot = 90,color=\"r\", figsize=(12,8))\n",
    "plt.title('Normalized Bar Chart of House prices in Reno, Nevada')\n",
    "plt.ylabel('Percentage of distribution')\n",
    "plt.xlabel('Price Intervals')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that more than 70% of houses are sold between $200-500k in Washoe County!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the most popular month houses are sold in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_month = residential_house['Sale Month'].value_counts(sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_month = sales_by_month.sort_index()\n",
    "\n",
    "sales_by_month = sales_by_month.rename({\n",
    "    1:'January',\n",
    "    2:'February',\n",
    "    3:'March',\n",
    "    4:'April',\n",
    "    5:'May',\n",
    "    6:'June',\n",
    "    7:'July',\n",
    "    8:'August',\n",
    "    9:'September',\n",
    "    10:'October',\n",
    "    11:'November',\n",
    "    12:'December',})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_by_month.plot.bar(color='r',figsize=(12,8))\n",
    "plt.title('Sales of Residential Houses by Month')\n",
    "plt.ylabel('Number of Houses Sold')\n",
    "plt.xlabel('Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the distribution looks relatively normal, but with a slight right skew. From this we can confidently say that houses are sold less in the first 4 months of the year than the last 8 months, with the summer months between June-August being the most popular and a steady decline of houses sold from August-December."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also can make a heatmap of the months to get help us get a better understanding of the months in comparison with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "\n",
    "sns.heatmap(sales_by_month.to_frame('Houses Sold').transpose(),\n",
    "            annot=True,cmap='magma',fmt='.2f')\n",
    "\n",
    "plt.title('Heatmap of Months vs. Houses Sold')\n",
    "plt.ylabel('Months')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to know what type of home buyers we are dealing with, so let's see where our home buyers are from!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(figsize=(12,8))\n",
    "\n",
    "sns.barplot(x=residential_house['State'].value_counts(normalize=True).head(5).values,\n",
    "            y=residential_house['State'].value_counts(normalize=True).index[:5])\n",
    "\n",
    "plt.title('Normalized Bar Chart of States Home Buyers are from')\n",
    "plt.xlabel('Percentage of Home Buyers')\n",
    "plt.ylabel('States')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, it looks like more than 90% are from Nevada while less than 10% are from CA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's look at what the general square footage of a house in Washoe County looks like just to help us visualize some more of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(residential_house['Bldg SF'],color='r')\n",
    "plt.title('Distribution Plot of Square Feet in Sold Houses')\n",
    "plt.xlabel('House Square Footage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is informative, but since the 'Year Blt' column is also available maybe we can extract some more useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should start by binning our values and then we can use the groupby method to see some of the different values based on binned years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By binning the year built column we can now continue to answer more questions such as,\n",
    "* Does buying a more recently built home have an affect on the size of the house?\n",
    "* Do more recently built homes tend to cost more than older homes and by how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [1900,1920,1940,1960,1970,1980,1990,2000,2010,2017]\n",
    "residential_house['Year bins'] = pd.cut(residential_house['Year Blt'],bins)\n",
    "residential_house['Year bins'].value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sq_ft = residential_house[['Bldg SF','Year bins']].groupby('Year bins').mean()\n",
    "\n",
    "fig,axes = plt.subplots(1,1,figsize=(12,8))\n",
    "\n",
    "sns.barplot(x=average_sq_ft.index.astype('str'),\n",
    "            y=average_sq_ft.values.reshape(len(average_sq_ft)),\n",
    "            ax=axes)\n",
    "\n",
    "plt.xlabel('Bins of Years')\n",
    "plt.ylabel('Average Square Footage')\n",
    "plt.title('Average Square Footage in Houses Sold in 2017 given by Binned Years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, this graph shows an increase in square footage as the years progress and also gives a good representation of the amount of space you could expect in a house built during a certain time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for the Sales Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_sq_ft = residential_house[['Sale Price','Year bins']].groupby('Year bins').mean()\n",
    "\n",
    "fig,axes = plt.subplots(1,1,figsize=(12,8))\n",
    "\n",
    "sns.barplot(x=average_sq_ft.index.astype('str'),\n",
    "            y=average_sq_ft.values.reshape(len(average_sq_ft)),\n",
    "            ax=axes)\n",
    "\n",
    "plt.xlabel('Bins of Years')\n",
    "plt.ylabel('Average Sales Price')\n",
    "plt.title('Average Sales Price of Houses Sold in 2017 given by Binned Years')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also see that you could generally expect to pay more for a house built more recently and less for an older home. Interestingly enough, we see a rise in home prices from 1920-1940, what this is accounted to is unknown to me. We could possibly account this to Washoe County being rather historical and the time between 1920-1940 being a special time in history, thus causing homes from that time period to cost more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preparing data for prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have visualized our data let's go ahead and try to make predictions for our data on the Sales Price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must first make sure our data is all in numeric form so that the models can be fit properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by looking at two of our columns 'Stories' and 'Grade'. We want to group similar values together so that the model can predict better and not have data values with only a few entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Grade'] = residential_house['Grade'].replace({'7.0 HIGH VALUE CLASS I':'Average',\n",
    "                                                                 '8.5 HIGH VALUE CLASS II/HIGH VALUE CLASS III':'Good-Very Good',\n",
    "                                                                 '9.0 HIGH VALUE CLASS III':'Very Good'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have simply replaced the 3 values with better corresponding groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will perform the same for the 'Stories' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Stories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Stories'].replace({'1.5 STRY FN':'SINGLE HALF STORY',\n",
    "                                     '2.5 STRY FN':'TWO HALF STORY',\n",
    "                                     '1.5 STRY UNF':'SINGLE HALF STORY',\n",
    "                                     'BI_LEVEL':'SPLIT LEVEL'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Stories'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And very similarly, we now have better grouped columns for our predictor values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at our data once more to see what columns we do not need for our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop a lot of these columns for predictions since they would not be very helpful to predict a Sales Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = [\n",
    "    'APN',\n",
    "    'Sale Verf',\n",
    "    'RecDoc',\n",
    "    'Subdivision',\n",
    "    'Avg Yr Blt',\n",
    "    'Total Units',\n",
    "    'TaxDist',\n",
    "    'LegalDesc',\n",
    "    'PriorPID',\n",
    "    'PriorOwner',\n",
    "    'Zip',\n",
    "    'State',\n",
    "    'City',\n",
    "    'Mailing1',\n",
    "    'Addl Owner',\n",
    "    'Owner1',\n",
    "    'Zoning',\n",
    "    'LUC at Sale',\n",
    "    'BldgType',\n",
    "    'Year bins'\n",
    "]\n",
    "\n",
    "residential_house.drop(drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have dropped our columns and are ready to proceed to making our predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Making Predictions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import our library functions from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what our current predictors looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define three of our methods here,\n",
    "* LabelEncoder() - to encode values numerically\n",
    "* StandardScaler() - to standardize the data for RFE\n",
    "* LinearRegression() - to predict our Sales Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "sc = StandardScaler()\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use our Label encoder to encode the 'Grade' and 'Stories' columns we cleaned up earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residential_house['Grade'] = le.fit_transform(residential_house['Grade'])\n",
    "residential_house['Stories'] = le.fit_transform(residential_house['Stories'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have encoded the string columns we wanted, let's get rid of the rest of the categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [columns \n",
    "               for columns \n",
    "               in residential_house.dtypes.index \n",
    "               if residential_house.dtypes[columns] == 'object']\n",
    "\n",
    "residential_house.drop(categorical,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must define our X and Y, Y will be assigned to the 'Sale Price' column and X will be the rest of the columns we prepared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also save the name of the columns and then standardize our data for RFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RFE stands for Recursive Feature Elimination, using this we may assign weights to our features and learn which is the most important towards our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = residential_house['Sale Price']\n",
    "X = residential_house.drop(['Sale Price'],axis=1)\n",
    "\n",
    "old_columns = X.columns\n",
    "X = sc.fit_transform(X)\n",
    "X = pd.DataFrame(X,columns=old_columns)\n",
    "\n",
    "# We tell RFE to use LinearRegression as the model, rank 4 features the best, and only dispose of 1 \n",
    "# feature at a time each iteration\n",
    "selector = RFE(lm,4,1)\n",
    "selector = selector.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we may now look at the rankings in order of column position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.ranking_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only are interested in the 4 best columns, so we can drop all the rest using list comprehension and the drop function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_not_one = [i \n",
    "                   for (i,x) \n",
    "                   in enumerate(selector.ranking_) \n",
    "                   if (x != 1)]\n",
    "\n",
    "print(columns_not_one)\n",
    "\n",
    "X.drop(X.columns[columns_not_one],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may now see what columns are left as predictors for Sales Price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just look at the data and make sure everything is okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must split our data into two sets: a train set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now fit our model using the training set and training y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our model is trained we can use the test set as 'new data' and test the accuracy of our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using and R_squared score we may look at the accuracy between our predicted values and the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(r2_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our predictions are at 58%, this is not bad, but not great either. We could improve this by adding more features, possibly incoporating market trends for housing, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's plot our residuals to make sure it is normal and centered around 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "sns.distplot(predictions-y_test,color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We have residuals that look normal and seem to be very close to a mean of 0 indicating a good linear model fit. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
